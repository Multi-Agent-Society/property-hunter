{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cc502d-654e-4a69-b8fa-5c863e3f21be",
   "metadata": {},
   "source": [
    "# CrewAI `property-hunter` Implementation\n",
    "\n",
    "Bringing together the crew for property hunting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db27298-6693-40f9-9066-696b2506dc19",
   "metadata": {},
   "source": [
    "### Boilerplate Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ffb92-a23a-4883-9617-3934e1791e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from crewai import Agent, Crew, Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2613064-048e-4908-bffe-5c2bfe683297",
   "metadata": {},
   "source": [
    "### Define LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92613aea-fddd-48a2-9444-086272d94ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ethan, this section requires some modification and decision making. \n",
    "You mentioned in Discord that you got Llama2 working in a docker container but \n",
    "it's very slow and not suitable for production or as an agent. \n",
    "\n",
    "Keep in mind, we may utilize different LLMs for different agents.\n",
    "\n",
    "We have several options to proceed:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1f23b9-6980-4f73-bc7a-e5b7b85365fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Utilize the official API hosted by OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-openai-api-key'\n",
    "# We don't need to set this environment variable, as it defaults to the official API endpoint. \n",
    "# os.environ[\"OPENAI_API_BASE\"] = ''           \n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo' # Adjust based on available model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44cd5a-2d2f-4e82-8134-ded925095168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Connect to Open Source Model Running Locally w/ Ollama\n",
    "''' This option has already been implemented without much success'''\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY=\"ollama\"\n",
    "llm = ChatOpenAI(\n",
    "    model = 'llama2:latest',  # Adjust based on available model\n",
    "    base_url = \"http://localhost:11434/v1\"\n",
    ")\n",
    "\n",
    "### you will pass \"llm\" to your agent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4cae5-ae0f-4471-a135-6fdd6a206379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: From HuggingFaceHub endpoint\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    huggingfacehub_api_token=\"<HF_TOKEN_HERE>\",\n",
    "    task=\"text-generation\",\n",
    ")\n",
    "\n",
    "### you will pass \"llm\" to your agent function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa0bf0-d9ca-4333-be69-07e32476144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 4: Your own HuggingFace endpoint\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    endpoint_url=\"<YOUR_ENDPOINT_URL_HERE>\",\n",
    "    huggingfacehub_api_token=\"<HF_TOKEN_HERE>\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    role=\"HuggingFace Agent\",\n",
    "    goal=\"Generate text using HuggingFace\",\n",
    "    backstory=\"A diligent explorer of GitHub docs.\",\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096f5c6-cd88-4b5e-84e1-fab43eaf3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 4: Mistral API\n",
    "MISTRAL_API_KEY=your-mistral-api-key\n",
    "MISTRAL_API_BASE=https://api.mistral.ai/v1\n",
    "MISTRAL_MODEL_NAME=\"mistral-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf410c-3246-4305-99ad-0857a6f0332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 5: Cohere\n",
    "from langchain_community.chat_models import ChatCohere\n",
    "\n",
    "# Initialize language model\n",
    "os.environ[\"COHERE_API_KEY\"] = \"your-cohere-api-key\"\n",
    "llm = ChatCohere()\n",
    "\n",
    "### you will pass \"llm\" to your agent function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8cf50-c9c9-4b8a-8bd7-ef5fb036e99f",
   "metadata": {},
   "source": [
    "## crewAI Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb87038-c96b-42cc-a834-a68f72d1824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
    "\n",
    "# # Initialize the tools\n",
    "# search_tool = SerperDevTool()\n",
    "# scrape_tool = ScrapeWebsiteTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a928d-3774-45a9-b490-6b102ae706a6",
   "metadata": {},
   "source": [
    "## Creating Agents\n",
    "\n",
    "- Define your Agents, and provide them a `role`, `goal` and `backstory`.\n",
    "- Agents will automatically use the model defined in the environment variable `os.environ[\"OPENAI_MODEL_NAME\"]` unless otherwise specified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c75a7-21d5-4bc3-8128-8fe6d5e60768",
   "metadata": {},
   "source": [
    "### Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b72900-83de-4419-b1c8-6dda2773669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = Agent(\n",
    "    role=\"\",\n",
    "    goal=\"\",\n",
    "    backstory=\"\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b87cf-de9d-47be-b85d-427794820880",
   "metadata": {},
   "source": [
    "### Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bdda80-741a-419b-85c4-d163b13e30ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = Agent(\n",
    "    role=\"\",\n",
    "    goal=\"\",\n",
    "    backstory=\"\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9ef0d-31a6-417c-a939-f89bb2b13984",
   "metadata": {},
   "source": [
    "### Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e58c46c-26b6-4545-b87d-c15d27870062",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = Agent(\n",
    "    role=\"\",\n",
    "    goal=\"\",\n",
    "    backstory=\"\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac5e17-4b3b-46a6-8ba7-6aa69e681ed2",
   "metadata": {},
   "source": [
    "## Creating Pydantic Object to Store Property Information\n",
    "\n",
    "- Create a class `PropertyDetails` using [Pydantic BaseModel](https://docs.pydantic.dev/latest/api/base_model/).\n",
    "- Agents will populate this object with information about different venues by creating different instances of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8cb722-936c-42e4-b363-df594784748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Features of the class should match the user's specification's \n",
    "which should be taken as input.\n",
    "\n",
    "Basic features such as `property_name`, `address`, `rent`, and `utilities`\n",
    "should always be returned\n",
    "'''\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class VenueDetails(BaseModel):\n",
    "    property_name: str\n",
    "    address: str\n",
    "    rent: int\n",
    "    utilities: str\n",
    "    feature_5: str\n",
    "    feature_6: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062458d-dd29-453e-afb6-8dbd2f295eb3",
   "metadata": {},
   "source": [
    "## Creating Tasks\n",
    "\n",
    "- Define your Tasks, and provide them a `description`, `expected_output` and `agent`.\n",
    "- By using `output_json`, you can specify the structure of the output you want.\n",
    "- By using `output_file`, you can get your output in a file.\n",
    "- By setting `human_input=True`, the task will ask for human feedback before finalising it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df3ffd-7efa-4692-9f0a-8a4bec68be6c",
   "metadata": {},
   "source": [
    "### Task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5a37d-bf0b-434e-b38f-a9660343d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = Task(\n",
    "    description=(\"\"),\n",
    "    expected_output=\"\",\n",
    "    agent=agent_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc8656-415b-45e3-8cfd-cdae68579ab0",
   "metadata": {},
   "source": [
    "### Task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad2cd7-b92b-4de1-af47-283ac4e0eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = Task(\n",
    "    description=(\"\"),\n",
    "    expected_output=\"\",\n",
    "    agent=agent_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe5dc5-b050-4620-a4b8-b688b6850ffa",
   "metadata": {},
   "source": [
    "### Task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e6cc6-0487-4458-baac-c649b6bba0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = Task(\n",
    "    description=(\"\"),\n",
    "    expected_output=\"\",\n",
    "    agent=agent_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011722f-a26e-4db5-981d-b85f31383826",
   "metadata": {},
   "source": [
    "## Creating the Crew\n",
    "\n",
    "- Create your crew of Agents\n",
    "- Pass the tasks to be performed by those agents.\n",
    "- `verbose=2` allows you to see all the logs of the execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0378f9-c2c9-486c-b81b-8fd4063cd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[],\n",
    "    tasks=[],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c41ce-ec9a-42a0-8285-4bcf061e3adb",
   "metadata": {},
   "source": [
    "## Running the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fb520-4ee4-4f75-a64b-a0a646639974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user_specifications\n",
    "user_specifications = {\n",
    "    'event_topic': \"Tech Innovation Conference\",\n",
    "    'event_description': \"A gathering of tech innovators \"\n",
    "                         \"and industry leaders \"\n",
    "                         \"to explore future technologies.\",\n",
    "    'event_city': \"San Francisco\",\n",
    "    'tentative_date': \"2024-09-15\",\n",
    "    'expected_participants': 500,\n",
    "    'budget': 20000,\n",
    "    'venue_type': \"Conference Hall\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be6f2d-406b-4e81-b645-6f26f7d65e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = crew.kickoff(inputs=user_specifications)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
